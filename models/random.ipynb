{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy tensorflow keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import keras_tuner as kt  # For hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 81 training relations, 81 validation, 81 test.\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir):\n",
    "    train_file = os.path.join(data_dir, \"train.json\")\n",
    "    val_file = os.path.join(data_dir, \"val.json\")\n",
    "    test_file = os.path.join(data_dir, \"test.json\")\n",
    "\n",
    "    with open(train_file, \"r\") as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(val_file, \"r\") as f:\n",
    "        val_data = json.load(f)\n",
    "    with open(test_file, \"r\") as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "data_dir = \"../dataset\"  # Move out of 'models' and into 'dataset'\n",
    "train_data, val_data, test_data = load_data(data_dir)\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training relations, {len(val_data)} validation, {len(test_data)} test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: Employed by Australian National Airways (ANA) after leaving the Air Force, Lukis become airfield manager at [E1S] Essendon [E1E], [E2S] Melbourne [E2E].\n",
      "Label dictionary: {'P931': 0, 'P4552': 1, 'P140': 2, 'P1923': 3, 'P150': 4, 'P6': 5, 'P27': 6, 'P449': 7, 'P1435': 8, 'P175': 9, 'P1344': 10, 'P39': 11, 'P527': 12, 'P740': 13, 'P706': 14, 'P84': 15, 'P495': 16, 'P123': 17, 'P57': 18, 'P22': 19, 'P178': 20, 'P241': 21, 'P403': 22, 'P1411': 23, 'P135': 24, 'P991': 25, 'P156': 26, 'P176': 27, 'P31': 28, 'P1877': 29, 'P102': 30, 'P1408': 31, 'P159': 32, 'P3373': 33, 'P1303': 34, 'P17': 35, 'P106': 36, 'P551': 37, 'P937': 38, 'P355': 39, 'P710': 40, 'P137': 41, 'P674': 42, 'P466': 43, 'P136': 44, 'P306': 45, 'P127': 46, 'P400': 47, 'P974': 48, 'P1346': 49, 'P460': 50, 'P86': 51, 'P118': 52, 'P264': 53, 'P750': 54, 'P58': 55, 'P3450': 56, 'P105': 57, 'P276': 58, 'P101': 59, 'P407': 60, 'P1001': 61, 'P800': 62, 'P131': 63, 'P177': 64, 'P364': 65, 'P2094': 66, 'P361': 67, 'P641': 68, 'P59': 69, 'P413': 70, 'P206': 71, 'P412': 72, 'P155': 73, 'P26': 74, 'P410': 75, 'P25': 76, 'P463': 77, 'P40': 78, 'P921': 79, 'NA': 80}\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "    texts, labels = [], []\n",
    "    label_dict = {}\n",
    "    label_index = 0\n",
    "\n",
    "    for relation, samples in data.items():\n",
    "        if relation not in label_dict:\n",
    "            label_dict[relation] = label_index\n",
    "            label_index += 1\n",
    "\n",
    "        for sample in samples:\n",
    "            # No need to join, it's already a string\n",
    "            texts.append(sample[\"tokens\"])\n",
    "            labels.append(label_dict[relation])\n",
    "\n",
    "    return texts, np.array(labels), label_dict\n",
    "\n",
    "\n",
    "train_texts, train_labels, label_dict = preprocess_data(train_data)\n",
    "val_texts, val_labels, _ = preprocess_data(val_data)\n",
    "test_texts, test_labels, _ = preprocess_data(test_data)\n",
    "\n",
    "print(f\"Sample text: {train_texts[0]}\")\n",
    "print(f\"Label dictionary: {label_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Baseline Accuracy: 0.0145\n",
      "Random Baseline Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0220    0.0286    0.0248        70\n",
      "           1     0.0120    0.0143    0.0131        70\n",
      "           2     0.0119    0.0143    0.0130        70\n",
      "           3     0.0112    0.0143    0.0126        70\n",
      "           4     0.0000    0.0000    0.0000        70\n",
      "           5     0.0260    0.0286    0.0272        70\n",
      "           6     0.0154    0.0143    0.0148        70\n",
      "           7     0.0111    0.0143    0.0125        70\n",
      "           8     0.0294    0.0286    0.0290        70\n",
      "           9     0.0000    0.0000    0.0000        70\n",
      "          10     0.0779    0.0857    0.0816        70\n",
      "          11     0.0149    0.0143    0.0146        70\n",
      "          12     0.0116    0.0143    0.0128        70\n",
      "          13     0.0143    0.0143    0.0143        70\n",
      "          14     0.0303    0.0286    0.0294        70\n",
      "          15     0.0000    0.0000    0.0000        70\n",
      "          16     0.0000    0.0000    0.0000        70\n",
      "          17     0.0141    0.0143    0.0142        70\n",
      "          18     0.0135    0.0143    0.0139        70\n",
      "          19     0.0152    0.0143    0.0147        70\n",
      "          20     0.0130    0.0143    0.0136        70\n",
      "          21     0.0000    0.0000    0.0000        70\n",
      "          22     0.0149    0.0143    0.0146        70\n",
      "          23     0.0000    0.0000    0.0000        70\n",
      "          24     0.0135    0.0143    0.0139        70\n",
      "          25     0.0000    0.0000    0.0000        70\n",
      "          26     0.0000    0.0000    0.0000        70\n",
      "          27     0.0000    0.0000    0.0000        70\n",
      "          28     0.0116    0.0143    0.0128        70\n",
      "          29     0.0000    0.0000    0.0000        70\n",
      "          30     0.0263    0.0286    0.0274        70\n",
      "          31     0.0000    0.0000    0.0000        70\n",
      "          32     0.0000    0.0000    0.0000        70\n",
      "          33     0.0000    0.0000    0.0000        70\n",
      "          34     0.0133    0.0143    0.0138        70\n",
      "          35     0.0294    0.0286    0.0290        70\n",
      "          36     0.0145    0.0143    0.0144        70\n",
      "          37     0.0143    0.0143    0.0143        70\n",
      "          38     0.0000    0.0000    0.0000        70\n",
      "          39     0.0000    0.0000    0.0000        70\n",
      "          40     0.0000    0.0000    0.0000        70\n",
      "          41     0.0286    0.0286    0.0286        70\n",
      "          42     0.0000    0.0000    0.0000        70\n",
      "          43     0.0000    0.0000    0.0000        70\n",
      "          44     0.0400    0.0429    0.0414        70\n",
      "          45     0.0133    0.0143    0.0138        70\n",
      "          46     0.0375    0.0429    0.0400        70\n",
      "          47     0.0000    0.0000    0.0000        70\n",
      "          48     0.0357    0.0429    0.0390        70\n",
      "          49     0.0000    0.0000    0.0000        70\n",
      "          50     0.0154    0.0143    0.0148        70\n",
      "          51     0.0000    0.0000    0.0000        70\n",
      "          52     0.0580    0.0571    0.0576        70\n",
      "          53     0.0000    0.0000    0.0000        70\n",
      "          54     0.0270    0.0286    0.0278        70\n",
      "          55     0.0357    0.0429    0.0390        70\n",
      "          56     0.0000    0.0000    0.0000        70\n",
      "          57     0.0270    0.0286    0.0278        70\n",
      "          58     0.0130    0.0143    0.0136        70\n",
      "          59     0.0141    0.0143    0.0142        70\n",
      "          60     0.0120    0.0143    0.0131        70\n",
      "          61     0.0000    0.0000    0.0000        70\n",
      "          62     0.0143    0.0143    0.0143        70\n",
      "          63     0.0548    0.0571    0.0559        70\n",
      "          64     0.0000    0.0000    0.0000        70\n",
      "          65     0.0000    0.0000    0.0000        70\n",
      "          66     0.0000    0.0000    0.0000        70\n",
      "          67     0.0154    0.0143    0.0148        70\n",
      "          68     0.0000    0.0000    0.0000        70\n",
      "          69     0.0000    0.0000    0.0000        70\n",
      "          70     0.0000    0.0000    0.0000        70\n",
      "          71     0.0135    0.0143    0.0139        70\n",
      "          72     0.0133    0.0143    0.0138        70\n",
      "          73     0.0120    0.0143    0.0131        70\n",
      "          74     0.0533    0.0571    0.0552        70\n",
      "          75     0.0000    0.0000    0.0000        70\n",
      "          76     0.0000    0.0000    0.0000        70\n",
      "          77     0.0133    0.0143    0.0138        70\n",
      "          78     0.0000    0.0000    0.0000        70\n",
      "          79     0.0149    0.0143    0.0146        70\n",
      "          80     0.1324    0.0218    0.0375       412\n",
      "\n",
      "    accuracy                         0.0145      6012\n",
      "   macro avg     0.0145    0.0140    0.0137      6012\n",
      "weighted avg     0.0212    0.0145    0.0151      6012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get unique relation labels\n",
    "num_classes = len(label_dict)\n",
    "\n",
    "# Generate random predictions\n",
    "random_predictions = np.random.randint(0, num_classes, size=len(test_labels))\n",
    "\n",
    "# Compute accuracy\n",
    "random_acc = accuracy_score(test_labels, random_predictions)\n",
    "\n",
    "# Generate a classification report\n",
    "random_report = classification_report(test_labels, random_predictions, digits=4, zero_division=0)\n",
    "\n",
    "print(f\"Random Baseline Accuracy: {random_acc:.4f}\")\n",
    "print(\"Random Baseline Classification Report:\")\n",
    "print(random_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
